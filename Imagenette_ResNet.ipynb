{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from lime import lime_image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from VCWA import Common, AttentionModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.applications.ResNet50V2(input_shape=(32, 32, 3), classes=10, weights=None).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005851fc",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f40531",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 10\n",
    "epochs = 5\n",
    "dataset = \"imagenette\"\n",
    "batch_size = 16\n",
    "path = \"D:/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7c394",
   "metadata": {},
   "source": [
    "### Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path + 'datasets/imagenette2/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        path + 'datasets/imagenette2/val',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5775",
   "metadata": {},
   "source": [
    "### Altermative CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82989f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6098270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc343f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar100_helper_generator(x, y):\n",
    "    while True:\n",
    "        for i in range(0, len(x), 25):\n",
    "            yield (\n",
    "                Common.resize_video(x[i:i+25], (224, 224))/255. ,\n",
    "                tf.keras.utils.to_categorical(y[i:i+25], 100)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7437e1",
   "metadata": {},
   "source": [
    "## Vanilla ResNet50v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2604bb94",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50 = tf.keras.models.load_model(\"models/imagenette2/base_resnet50v2\")\n",
    "resnet50 = tf.keras.applications.ResNet50V2(input_shape=input_shape, classes=classes, weights=None)\n",
    "\n",
    "resnet50.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + resnet50.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "resnet50.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[resnet50_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.save(\"models/\" + dataset + \"/\" + resnet50.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf14877",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(resnet50, test_generator, CAM_layer=\"conv5_block3_3_conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4743739",
   "metadata": {},
   "source": [
    "### lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbcf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    resnet50.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf024c",
   "metadata": {},
   "source": [
    "## L2PA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32cf9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load\n",
    "\n",
    "L2PA_model = AttentionModels.create_L2PA_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657eda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + L2PA_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "L2PA_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[L2PA_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_model.save(\"models/\" + dataset + \"/\" + L2PA_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca465f7c",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c907b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(L2PA_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d754e",
   "metadata": {},
   "source": [
    "## Attention Gated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eaaa9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gated_model = tf.keras.models.load_model(\"models/imagenette2/AttentionGated_ResNet50v2\")\n",
    "#gated_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "gated_model = AttentionModels.create_AttentionGated_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + gated_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "gated_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[gated_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_model.save(\"models/\" + dataset + \"/\" + gated_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76295920",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_extractor = AttentionModels.get_attention_extractor(gated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d408fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)\n",
    "#X, Y = next(cifar100_helper_generator(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c389e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, a1, a2, a3 = gated_extractor.predict(X)\n",
    "\n",
    "i = 3\n",
    "\n",
    "overlay = overlay = Common.combine_attention([a1[i], a2[i], a3[i]])\n",
    "combined_image = Common.overlay_attention(X[i], overlay)\n",
    "Common.display_attention_maps(X[i], [combined_image, a1[i], a2[i], a3[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89682279",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    gated_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86459d63",
   "metadata": {},
   "source": [
    "## Attention Gated with Grid Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cda35",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb022638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gatedgrid_model = tf.keras.models.load_model(\"models/imagenette2/AttentionGatedGrid_ResNet50v2\")\n",
    "#gatedgrid_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "gatedgrid_model = AttentionModels.create_AttentionGatedGrid_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + gatedgrid_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "gatedgrid_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[gatedgrid_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_model.save(\"models/\" + dataset + \"/\" + gatedgrid_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47a78b",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532957a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_attention_batch(gatedgrid_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705456f",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0fb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    gatedgrid_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5c76f",
   "metadata": {},
   "source": [
    "## Residual Attention Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2258a8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual_attention_model = tf.keras.models.load_model(\"models/imagenette2/ResidualAttentionNet50v2\")\n",
    "#residual_attention_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "\n",
    "residual_attention_model = AttentionModels.create_ResidualAttention_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843932",
   "metadata": {},
   "outputs": [],
   "source": [
    "residualattention_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + residual_attention_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "residual_attention_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[residualattention_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_attention_model.save(\"models/\" + dataset + \"/\" + residual_attention_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c8cd",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae2c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_attention_batch(residual_attention_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d966870",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[3].astype('double'), \n",
    "    residual_attention_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefdbed",
   "metadata": {},
   "source": [
    "## CBAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128d8c1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CBAM_model = tf.keras.models.load_model(\"models/imagenette2/CBAM_ResNet50v2\")\n",
    "#CBAM_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "CBAM_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbam_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + CBAM_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "CBAM_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[cbam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBAM_model.save(\"models/\" + dataset + \"/\" + CBAM_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8eccf1",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbdd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(resnet50, test_generator, CAM_layer=\"conv5_block3_3_conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb4a76",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    CBAM_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.85px",
    "left": "1549px",
    "right": "20px",
    "top": "120px",
    "width": "358px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
