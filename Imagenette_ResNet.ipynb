{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from VCWA import Common, AttentionModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005851fc",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7c394",
   "metadata": {},
   "source": [
    "### Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 10\n",
    "epochs = 100\n",
    "dataset = \"imagenette\"\n",
    "batch_size = 16\n",
    "path = \"D:/\"\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path + 'datasets/imagenette2/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    path + 'datasets/imagenette2/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5775",
   "metadata": {},
   "source": [
    "### CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "classes = 100\n",
    "epochs = 100\n",
    "dataset = \"cifar-100\"\n",
    "batch_size = 256\n",
    "path = \"D:/\"\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "train_generator = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(x_train/255, tf.float32),\n",
    "            tf.cast(tf.keras.utils.to_categorical(y_train), tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "train_generator = train_generator.batch(batch_size)\n",
    "\n",
    "test_generator = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(x_test/255, tf.float32),\n",
    "            tf.cast(tf.keras.utils.to_categorical(y_test), tf.int32)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "test_generator = test_generator.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7437e1",
   "metadata": {},
   "source": [
    "## Vanilla ResNet50v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bace23",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet50 = tf.keras.models.load_model(\"models/imagenette2/base_resnet50v2\")\n",
    "resnet50 = tf.keras.applications.ResNet50V2(input_shape=input_shape, classes=classes, weights=None)\n",
    "\n",
    "resnet50.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4bbb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet50_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + resnet50.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "resnet50.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[resnet50_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.save(\"models/\" + dataset + \"/\" + resnet50.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b230b2",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(resnet50, test_generator, CAM_layer=\"conv5_block3_3_conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4743739",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753109b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_lime_batch(resnet50, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf024c",
   "metadata": {},
   "source": [
    "## L2PA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32cf9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load\n",
    "\n",
    "L2PA_model = AttentionModels.create_L2PA_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657eda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + L2PA_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "L2PA_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[L2PA_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_model.save(\"models/\" + dataset + \"/\" + L2PA_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca465f7c",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(L2PA_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3e9b93",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30509d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(L2PA_model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d754e",
   "metadata": {},
   "source": [
    "## Attention Gated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eaaa9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152749",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gated_model = tf.keras.models.load_model(\"models/imagenette2/AttentionGated_ResNet50v2\")\n",
    "#gated_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "gated_model = AttentionModels.create_AttentionGated_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + gated_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "gated_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[gated_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_model.save(\"models/\" + dataset + \"/\" + gated_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76295920",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(gated_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89682279",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(gated_model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86459d63",
   "metadata": {},
   "source": [
    "## Attention Gated with Grid Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cda35",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb022638",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gatedgrid_model = tf.keras.models.load_model(\"models/imagenette2/AttentionGatedGrid_ResNet50v2\")\n",
    "#gatedgrid_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "gatedgrid_model = AttentionModels.create_AttentionGatedGrid_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + gatedgrid_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "gatedgrid_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[gatedgrid_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_model.save(\"models/\" + dataset + \"/\" + gatedgrid_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47a78b",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5ba0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_attention_batch(gatedgrid_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705456f",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ec619",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(gatedgrid_model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5c76f",
   "metadata": {},
   "source": [
    "## Residual Attention Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2258a8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#residual_attention_model = tf.keras.models.load_model(\"models/imagenette2/ResidualAttentionNet50v2\")\n",
    "#residual_attention_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "\n",
    "residual_attention_model = AttentionModels.create_ResidualAttention_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843932",
   "metadata": {},
   "outputs": [],
   "source": [
    "residualattention_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + residual_attention_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "residual_attention_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[residualattention_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_attention_model.save(\"models/\" + dataset + \"/\" + residual_attention_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c8cd",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba3536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_attention_batch(residual_attention_model, test_generator, use_attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d966870",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e302bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(residual_attention_model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefdbed",
   "metadata": {},
   "source": [
    "## CBAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128d8c1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CBAM_model = tf.keras.models.load_model(\"models/imagenette2/CBAM_ResNet50v2\")\n",
    "#CBAM_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "CBAM_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=input_shape, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbam_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + CBAM_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "CBAM_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[cbam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBAM_model.save(\"models/\" + dataset + \"/\" + CBAM_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8eccf1",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(CBAM_model, test_generator, CAM_layer=\"conv5_block3_3_conv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb4a76",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(CBAM_model, test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.85px",
    "left": "1538px",
    "right": "20px",
    "top": "121px",
    "width": "358px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
