{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import tensorflow as tf\n",
    "import Common\n",
    "import datetime\n",
    "import AttentionModels\n",
    "from lime import lime_image\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005851fc",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7c394",
   "metadata": {},
   "source": [
    "### Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    #rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'D:/datasets/imagenette2/train',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input) #rescale=1./255)\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        'D:/datasets/imagenette2/val',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5775",
   "metadata": {},
   "source": [
    "### Altermative CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82989f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.cifar100.load_data(label_mode=\"fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc343f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cifar100_helper_generator(x, y):\n",
    "    while True:\n",
    "        for i in range(0, len(x), 25):\n",
    "            yield (\n",
    "                Common.resize_video(x[i:i+25], (224, 224))/255. ,\n",
    "                tf.keras.utils.to_categorical(y[i:i+25], 100)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7437e1",
   "metadata": {},
   "source": [
    "## Vanilla ResNet50v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = tf.keras.models.load_model(\"models/imagenette2/base_resnet50v2\")\n",
    "#resnet50 = tf.keras.applications.ResNet50V2(classes=10, weights=None)\n",
    "\n",
    "resnet50.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/resnet50v2_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "resnet50.fit(train_generator, \n",
    "             epochs=100,\n",
    "             validation_data=test_generator,\n",
    "             callbacks=[tensorboard_callback])\n",
    "#rsnet50.fit(cifar100_helper_generator(x_train, y_train), steps_per_epoch=2000, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.save(\"models/imagenette2/base_resnet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4743739",
   "metadata": {},
   "source": [
    "### lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbcf024",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    resnet50.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf024c",
   "metadata": {},
   "source": [
    "## L2PA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32cf9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_model = AttentionModels.create_L2PA_ResNet50v2(input_shape=(224, 224, 3), num_classes=10)\n",
    "#fit_model = AttentionModels.create_L2PA_ResNet50v2(input_shape=(224, 224, 3), num_classes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657eda60",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/l2pa_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "L2PA_model.fit(train_generator, \n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[tensorboard_callback])\n",
    "#fit_model.fit(cifar100_helper_generator(x_train, y_train), steps_per_epoch=2000, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_model.save(\"models/imagenette2/L2PA_resnet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca465f7c",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb135dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_extractor = AttentionModels.get_attention_extractor(L2PA_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e24e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)\n",
    "#X, Y = next(cifar100_helper_generator(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, a1, a2, a3 = L2PA_extractor.predict(X)\n",
    "\n",
    "i = 1\n",
    "\n",
    "overlay = overlay = Common.combine_attention([a1[i], a2[i], a3[i]])\n",
    "combined_image = Common.overlay_attention(X[i], overlay)\n",
    "Common.display_attention_maps(X[i], [combined_image, a1[i], a2[i], a3[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d754e",
   "metadata": {},
   "source": [
    "## Attention Gated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eaaa9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152749",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_model = tf.keras.models.load_model(\"models/imagenette2/AttentionGated_ResNet50v2\")\n",
    "gated_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#gated_model = AttentionModels.create_AttentionGated_ResNet50v2(input_shape=(224, 224, 3), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/gated_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "gated_model.fit(\n",
    "    train_generator, \n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_model.save(\"models/imagenette2/AttentionGated_ResNet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76295920",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f757dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_extractor = AttentionModels.get_attention_extractor(gated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d408fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)\n",
    "#X, Y = next(cifar100_helper_generator(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c389e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, a1, a2, a3 = gated_extractor.predict(X)\n",
    "\n",
    "i = 3\n",
    "\n",
    "overlay = overlay = Common.combine_attention([a1[i], a2[i], a3[i]])\n",
    "combined_image = Common.overlay_attention(X[i], overlay)\n",
    "Common.display_attention_maps(X[i], [combined_image, a1[i], a2[i], a3[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89682279",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023e9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    gated_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86459d63",
   "metadata": {},
   "source": [
    "## Attention Gated with Grid Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cda35",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb022638",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_model = tf.keras.models.load_model(\"models/imagenette2/AttentionGatedGrid_ResNet50v2\")\n",
    "gatedgrid_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "#gatedgrid_model = AttentionModels.create_AttentionGatedGrid_ResNet50v2(input_shape=(224, 224, 3), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/gatedgrid_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "gatedgrid_model.fit(\n",
    "    train_generator, \n",
    "    epochs=100,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_model.save(\"models/imagenette2/AttentionGatedGrid_ResNet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47a78b",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f891efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_extractor = AttentionModels.get_attention_extractor(gatedgrid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)\n",
    "#X, Y = next(cifar100_helper_generator(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b279114",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, a1, a2, a3 = gatedgrid_extractor.predict(X)\n",
    "\n",
    "i = 8\n",
    "\n",
    "overlay = overlay = Common.combine_attention([a1[i], a2[i], a3[i]])\n",
    "combined_image = Common.overlay_attention(X[i], overlay)\n",
    "Common.display_attention_maps(X[i], [combined_image, a1[i], a2[i], a3[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705456f",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0fb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    gatedgrid_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5c76f",
   "metadata": {},
   "source": [
    "## Residual Attention Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2258a8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual_attention_model = tf.keras.models.load_model(\"models/imagenette2/ResidualAttentionNet50v2\")\n",
    "\n",
    "residual_attention_model = AttentionModels.create_ResidualAttention_ResNet50v2(input_shape=(224, 224, 3), num_classes=10)\n",
    "\n",
    "residual_attention_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843932",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/residualattention_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "residual_attention_model.fit(train_generator, \n",
    "    epochs=1,\n",
    "    validation_data=test_generator),\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_attention_model.save(\"models/imagenette2/ResidualAttentionNet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c8cd",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becead18",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_attention_extractor = AttentionModels.get_attention_extractor(residual_attention_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d15366",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a012c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, a1, a2, a3 = residual_attention_extractor(X)\n",
    "\n",
    "i = 1\n",
    "\n",
    "overlay = overlay = Common.combine_attention([a1[i], a2[i], a3[i]])\n",
    "combined_image = Common.overlay_attention(X[i], overlay)\n",
    "Common.display_attention_maps(X[i], [combined_image, a1[i], a2[i], a3[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d966870",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6f7ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "explanation = explainer.explain_instance(\n",
    "    X[1].astype('double'), \n",
    "    residual_attention_model.predict, top_labels=5,\n",
    "    hide_color=0, \n",
    "    num_samples=1000)\n",
    "\n",
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.85px",
    "left": "1549px",
    "right": "20px",
    "top": "120px",
    "width": "358px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
