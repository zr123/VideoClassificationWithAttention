{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import Models\n",
    "import AttentionModels\n",
    "import Common\n",
    "import VideoDataGenerator\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7b37b",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose split\n",
    "split_no = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27835f1b",
   "metadata": {},
   "source": [
    "### HMDB51 Video Data with 25 Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0366252",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Common.evaluate_dataset(\"D:/processed_datasets/hmdb51_vid25/\")\n",
    "split_df = Common.get_hmdb51_split(\"D:/datasets/hmdb51_org_splits\", split_no=split_no)\n",
    "hmdb51_video_dataset = dataset.merge(split_df, on=\"filename\")\n",
    "# encode y\n",
    "hmdb51_video_dataset.category = preprocessing.LabelEncoder().fit_transform(hmdb51_video_dataset.category)\n",
    "hmdb51_video_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d39b2f",
   "metadata": {},
   "source": [
    "### HMDB51 OptFlow Data based on 25 Frames with L=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Common.evaluate_dataset(\"D:/processed_datasets/hmdb51_optflowl1_npz25/\")\n",
    "split_df = Common.get_hmdb51_split(\"D:/datasets/hmdb51_org_splits\", split_no=split_no)\n",
    "# fix file type extensions\n",
    "split_df[\"filename\"] = split_df[\"filename\"].str.split(\".\", expand=True)[0] + \".npz\"\n",
    "hmdb51_optflow_dataset = dataset.merge(split_df, on=\"filename\")\n",
    "hmdb51_optflow_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b0d1e",
   "metadata": {},
   "source": [
    "### prepare VideoDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 1].path.tolist(),\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 1].category.tolist(),\n",
    "    num_classes = 51,\n",
    "    target_size=(224, 224),\n",
    "    optflow_path=hmdb51_optflow_dataset[hmdb51_optflow_dataset.split == 1].path.tolist(),\n",
    "    batch_size=1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 2].path.tolist(),\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 2].category.tolist(),\n",
    "    num_classes = 51,\n",
    "    target_size=(224, 224),\n",
    "    optflow_path=hmdb51_optflow_dataset[hmdb51_optflow_dataset.split == 2].path.tolist(),\n",
    "    batch_size=1,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da298448",
   "metadata": {},
   "source": [
    "## TwoStream-Network (BaseResnet50v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5500a5",
   "metadata": {},
   "source": [
    "### Pre-Training individual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e583dc",
   "metadata": {},
   "source": [
    "#### Video Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_train_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 1].path.tolist(),\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 1].category.tolist(),\n",
    "    num_classes = 51,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    shape_format=\"images\"\n",
    ")\n",
    "video_test_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 2].path.tolist(),\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 2].category.tolist(),\n",
    "    num_classes = 51,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=2,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    shape_format=\"images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5652ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=(224, 224, 3), classes=51)\n",
    "video_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_model.fit(video_train_gen, epochs=1, validation_data=video_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b521a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative: Use pretrained imagenet\n",
    "## video_model = tf.keras.applications.ResNet50V2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7dd15",
   "metadata": {},
   "source": [
    "#### OptFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30286c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_train_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_optflow_dataset[hmdb51_optflow_dataset.split == 1].path.tolist(),\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 1].category.tolist(),\n",
    "    num_classes = 51,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    shape_format=\"images\"\n",
    ")\n",
    "optflow_test_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_optflow_dataset[hmdb51_optflow_dataset.split == 2].path.tolist(),\n",
    "    hmdb51_video_dataset[hmdb51_video_dataset.split == 2].category.tolist(),\n",
    "    num_classes = 51,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=2,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    shape_format=\"images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=(224, 224, 2), classes=51)\n",
    "optflow_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_model.fit(optflow_train_gen, epochs=1, validation_data=optflow_test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959150c",
   "metadata": {},
   "source": [
    "### Training combined TwoStream Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_resnet50v2 = Models.assemble_TwoStreamModel(video_model, optflow_model, 51, fusion=\"average\", recreate_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit_twostream_25_L1/resnet50v2_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "twostream_resnet50v2.fit(\n",
    "    train_gen,\n",
    "    epochs=1,\n",
    "    validation_data=test_gen,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5007d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_resnet50v2.save(\"models/twostream_25_L1/ResNet50v2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "291.85px",
    "left": "1553px",
    "right": "20px",
    "top": "121px",
    "width": "346px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
