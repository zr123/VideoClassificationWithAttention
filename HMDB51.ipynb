{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f4b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from IPython.core.display import Image\n",
    "\n",
    "from VCWA import Models, AttentionModels, Common, VideoDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a7b37b",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6ddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mount cloud-storage bucket\n",
    "# !mkdir /home/jupyter/bucket\n",
    "!gcsfuse --implicit-dirs gfr-master-data-bucket /home/jupyter/bucket/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743bad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 256 # use 256 only for single-frame batches\n",
    "test_batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_no = 1\n",
    "\n",
    "path = \"D:/\"\n",
    "\n",
    "hmdb51_dataset = Common.get_dataset(\n",
    "    path + \"processed_datasets/hmdb51_vid25\", \n",
    "    path + \"datasets/hmdb51_org_splits\", \n",
    "    path + \"processed_datasets/hmdb51_optflowl10_npz25\", \n",
    "    split_no, \n",
    "    \"hmdb51\"\n",
    ")\n",
    "hmdb51_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83068c3",
   "metadata": {},
   "source": [
    "## TODO: 2D-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da298448",
   "metadata": {},
   "source": [
    "## TwoStream-Network (BaseResnet50v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5500a5",
   "metadata": {},
   "source": [
    "### Pre-Training individual Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e583dc",
   "metadata": {},
   "source": [
    "#### Video Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecc3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_train_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=train_batch_size,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    shape_format=\"images\",\n",
    "    single_frame=True,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "video_test_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=test_batch_size,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    shape_format=\"images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5652ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "# video_model = tf.keras.models.load_model(\"models/twostream_25_L10/ResNet50v2/video\")\n",
    "\n",
    "# Create new\n",
    "video_model = tf.keras.applications.ResNet50V2(input_shape=(224, 224, 3), classes=51, weights=None)\n",
    "# video_model = AttentionModels.create_ResidualAttention_ResNet50v2(input_shape=(224, 224, 3), classes=51)\n",
    "# video_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=(224, 224, 3), classes=51)\n",
    "\n",
    "\n",
    "video_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/fit_twostream_25_L10/video/\" + video_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_tensorboard_callback = tensorboard_callback\n",
    "\n",
    "video_model.fit(\n",
    "    video_train_gen, \n",
    "    epochs=10, \n",
    "    validation_data=video_test_gen,\n",
    "    validation_freq=5,\n",
    "    callbacks=[vid_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4cf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_model.evaluate(video_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_model.save(\"models/twostream_25_L10/video/\" + video_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf7dd15",
   "metadata": {},
   "source": [
    "#### OptFlow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30286c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_dataset = hmdb51_dataset.copy()\n",
    "del optflow_dataset[\"path\"]\n",
    "optflow_dataset.rename(columns = {\"optflow_path\": \"path\"}, inplace=True)\n",
    "\n",
    "optflow_train_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    optflow_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=train_batch_size,\n",
    "    preprocessing_function=None,\n",
    "    shape_format=\"images\",\n",
    "    single_frame=True,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "optflow_test_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    optflow_dataset,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=test_batch_size,\n",
    "    preprocessing_function=None,\n",
    "    shape_format=\"images\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "# video_model = tf.keras.models.load_model(\"models/twostream_25_L10/ResNet50v2/optflow\")\n",
    "\n",
    "# Create new\n",
    "#optflow_model = AttentionModels.create_ResidualAttention_ResNet50v2(input_shape=(224, 224, 20), classes=51)\n",
    "#optflow_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=(224, 224, 20), classes=51)\n",
    "#optflow_model = AttentionModels.tiny_cnn((224, 224, 20), 51, False)\n",
    "\n",
    "optflow_model = tf.keras.applications.ResNet50V2(input_shape=(224, 224, 20), classes=51, weights=None)\n",
    "\n",
    "optflow_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa02dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/fit_twostream_25_L10/optflow/\" + optflow_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14b01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_model.fit(\n",
    "    optflow_train_gen, \n",
    "    epochs=10, \n",
    "    validation_data=optflow_test_gen,\n",
    "    validation_freq=5,\n",
    "    callbacks=[optflow_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da33de",
   "metadata": {},
   "outputs": [],
   "source": [
    "optflow_model.save(\"models/twostream_25_L10/optflow/\" + optflow_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a959150c",
   "metadata": {},
   "source": [
    "### Training combined TwoStream Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99130d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_train_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_dataset,\n",
    "    target_size=(224, 224),\n",
    "    optflow=True,\n",
    "    batch_size=train_batch_size,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    single_frame=True,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "twostream_test_gen = VideoDataGenerator.VideoDataGenerator(\n",
    "    hmdb51_dataset,\n",
    "    target_size=(224, 224),\n",
    "    optflow=True,\n",
    "    batch_size=test_batch_size,\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream = Models.assemble_TwoStreamModel(video_model, optflow_model, 51, fusion=\"average\", recreate_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716c16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/fit_twostream_25_L10/twostream\" + twostream.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "twostream.fit(\n",
    "    twostream_train_gen,\n",
    "    epochs=1,\n",
    "    validation_data=twostream_test_gen,\n",
    "    validation_freq=10,\n",
    "    callbacks=[twostream_tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3306e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_resnet50v2.evaluate(twostream_test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5007d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "twostream_resnet50v2.save(\"models/twostream_25_L1/ResNet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d57ad77",
   "metadata": {},
   "source": [
    "### Display attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = twostream_test_gen.__getitem__(4)\n",
    "x_video, x_optflow = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd19a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199507b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = Models.get_twostream_attention(x_video[0], twostream_resnet50v2)\n",
    "Models.video_to_gif(attention, \"./attention.gif\")\n",
    "\n",
    "Image(filename=\"./attention.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183f18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam_attention = Models.get_twostream_gradcam(x_video[0], twostream_resnet50v2, \"conv5_block3_3_conv\")\n",
    "Models.video_to_gif(gradcam_attention, \"./gradcam_attention.gif\")\n",
    "\n",
    "Image(filename=\"./gradcam_attention.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b09c309",
   "metadata": {},
   "source": [
    "## Tests - Solostream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e572ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "\n",
    "def assemble_SoloStreamModel(spatial_stream_model, classes=51, fusion=\"average\", recreate_top=False):\n",
    "    spatial_stream_input = layers.Input(spatial_stream_model.inputs[0].shape)\n",
    "\n",
    "    if recreate_top:\n",
    "        spatial_stream = layers.TimeDistributed(Models.recreate_top_fn(spatial_stream_model, classes))(spatial_stream_input)\n",
    "    else:\n",
    "        spatial_stream = layers.TimeDistributed(spatial_stream_model)(spatial_stream_input)\n",
    "\n",
    "    # late fusion\n",
    "    if fusion == \"average\":\n",
    "        fusion = tf.math.reduce_mean(spatial_stream, axis=1)\n",
    "\n",
    "    model = Model(inputs=spatial_stream_input, outputs=fusion)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.Accuracy(), tf.keras.metrics.TopKCategoricalAccuracy(5)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b93fc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "solostream = assemble_SoloStreamModel(video_model, 51, fusion=\"average\", recreate_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "solostream.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=test_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a35d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "solostream.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=test_gen\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567cfb27",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b367a24",
   "metadata": {},
   "source": [
    "### Basenetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbc0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "basenet = tf.keras.applications.ResNet50V2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c1111",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172eadf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Models.assemble_lstm(basenet, classes=51, recreate_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit_lstm_25_L1/resnet50v2_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "lstm.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=test_gen,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save(\"models/lstm_25_L1/ResNet50v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563c56d",
   "metadata": {},
   "source": [
    "## TODO: 3D-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f95a76",
   "metadata": {},
   "source": [
    "## TODO: (2+1)D-CNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "564.85px",
    "left": "1551px",
    "right": "20px",
    "top": "118px",
    "width": "352px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
