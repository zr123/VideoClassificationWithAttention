{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4af6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from VCWA import Common, AttentionModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005851fc",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b7c394",
   "metadata": {},
   "source": [
    "### Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 10\n",
    "epochs = 100\n",
    "dataset = \"imagenette\"\n",
    "batch_size = 64\n",
    "path = \"D:/\"\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=0.0001)\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path + 'datasets/imagenette2/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    path + 'datasets/imagenette2/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c5775",
   "metadata": {},
   "source": [
    "### CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ddf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 100\n",
    "epochs = 100\n",
    "dataset = \"cifar-100\"\n",
    "batch_size = 64\n",
    "path = \"D:/\"\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=0.0001)\n",
    "\n",
    "\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=50.0,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    path + 'datasets/cifar100/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    path + 'datasets/cifar100/test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5065599",
   "metadata": {},
   "source": [
    "### CUB-200-2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "classes = 200\n",
    "epochs = 100\n",
    "dataset = \"cub-200\"\n",
    "batch_size = 64\n",
    "path = \"D:/\"\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, decay=0.0001)\n",
    "\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.resnet_v2.preprocess_input,\n",
    "    rotation_range=20.0,\n",
    "    shear_range=20.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, \n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path + 'datasets/CUB_200_2011/images',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    subset=\"training\")\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    path + 'datasets/CUB_200_2011/images',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7437e1",
   "metadata": {},
   "source": [
    "## Vanilla MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bace23",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46adb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mobilenet = tf.keras.models.load_model(\"models/\" + dataset + \"/mobilenetv2\")\n",
    "mobilenet = tf.keras.applications.MobileNetV2(input_shape=input_shape, classes=classes, weights=None)\n",
    "\n",
    "mobilenet.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b4bbb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mobilenet_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + resnet50.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "mobilenet.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[resnet50_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet.save(\"models/\" + dataset + \"/mobilenetv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b230b2",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea185235",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(mobilenet, x, CAM_layer=\"block_12_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753109b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_lime_batch(mobilenet, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbf024c",
   "metadata": {},
   "source": [
    "## L2PA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c32cf9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5bbac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2PA_model = tf.keras.models.load_model(\"models/\" + dataset + \"/L2PA_MobileNetV2\")\n",
    "L2PA_model = AttentionModels.create_L2PA_ResNet50v2(input_shape=input_shape, classes=classes)\n",
    "\n",
    "L2PA_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657eda60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L2PA_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + L2PA_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "L2PA_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[L2PA_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff1e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L2PA_model.save(\"models/\" + dataset + \"/\" + L2PA_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca465f7c",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9237db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f086a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(L2PA_model, x, use_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(L2PA_model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d754e",
   "metadata": {},
   "source": [
    "## Attention Gated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eaaa9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31152749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gated_model = tf.keras.models.load_model(\"models/\" + dataset + \"/AttGated_MobileNetV2\")\n",
    "gated_model = AttentionModels.create_AttentionGated_ResNet50v2(input_shape=input_shape, classes=classes)\n",
    "\n",
    "gated_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + gated_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "gated_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[gated_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gated_model.save(\"models/\" + dataset + \"/\" + gated_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76295920",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d8aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(gated_model, x, use_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(gated_model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86459d63",
   "metadata": {},
   "source": [
    "## Attention Gated with Grid Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31cda35",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb022638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gatedgrid_model = tf.keras.models.load_model(\"models/\" + dataset + \"/AttGatedGrid_MobileNetV2\")\n",
    "gatedgrid_model = AttentionModels.create_AttentionGatedGrid_ResNet50v2(input_shape=input_shape, classes=classes)\n",
    "\n",
    "gatedgrid_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + gatedgrid_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "gatedgrid_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[gatedgrid_tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gatedgrid_model.save(\"models/\" + dataset + \"/\" + gatedgrid_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47a78b",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe9c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c5ba0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_attention_batch(gatedgrid_model, x, use_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8ec619",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(gatedgrid_model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf5c76f",
   "metadata": {},
   "source": [
    "## Residual Attention Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2258a8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7c3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual_attention_model = tf.keras.models.load_model(\"models/\" + dataset + \"/ResAttentionMobileNetV2\")\n",
    "residual_attention_model = AttentionModels.create_ResidualAttention_ResNet50v2(input_shape=input_shape, classes=classes)\n",
    "\n",
    "residual_attention_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf843932",
   "metadata": {},
   "outputs": [],
   "source": [
    "residualattention_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + residual_attention_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "residual_attention_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[residualattention_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_attention_model.save(\"models/\" + dataset + \"/\" + residual_attention_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb0c8cd",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f063365",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba3536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Common.display_attention_batch(residual_attention_model, x, use_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e302bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(residual_attention_model, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cefdbed",
   "metadata": {},
   "source": [
    "## CBAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128d8c1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CBAM_model = tf.keras.models.load_model(\"models/\" + dataset + \"/CBAM_MobileNetV2\")\n",
    "CBAM_model = AttentionModels.create_CBAM_ResNet50v2(input_shape=input_shape, classes=classes)\n",
    "\n",
    "CBAM_model.compile(\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    optimizer=optimizer, \n",
    "    metrics=[\"accuracy\", tf.keras.metrics.TopKCategoricalAccuracy(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbam_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"logs/\" + dataset + \"/\" + CBAM_model.name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), \n",
    "    histogram_freq=1)\n",
    "\n",
    "CBAM_model.fit(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[cbam_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CBAM_model.save(\"models/\" + dataset + \"/\" + CBAM_model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8eccf1",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db02876",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = test_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8681f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_attention_batch(CBAM_model, x, CAM_layer=\"block_12_add\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common.display_lime_batch(CBAM_model, x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "367px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.85px",
    "left": "1538px",
    "right": "20px",
    "top": "121px",
    "width": "358px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
